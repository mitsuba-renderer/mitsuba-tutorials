{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Caustics optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial contains an advanced inverse rendering example: recover the surface displacement (heightmap)\n",
    "of a slab of glass such that light passing through it focuses into a specific desired image.\n",
    "\n",
    "This reproduces the results showcased in Section 4.3 of [Mitsuba 2: A Retargetable Forward and Inverse Renderer](https://rgl.epfl.ch/publications/NimierDavidVicini2019Mitsuba2).\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "✔️ **What will you learn?**\n",
    "\n",
    "- Creating a simple mesh from Python\n",
    "- Loading a scene define procedurally from Python\n",
    "- Applying a heightmap to a mesh from Python\n",
    "- Optimizing \"latent\" variables, i.e. variables which are not directly defined as part of the scene but affect it\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scene will be setup as follows:\n",
    "\n",
    "1. A directional area light (white or colorful, depending on the target image)\n",
    "2. Light from the emitter passes through a glass slab. We will optimize the slab's surface (via a heightmap)...\n",
    "3. ...so that light is focused on a receiving plane in a way that reproduces a desired target image.\n",
    "\n",
    "In order to efficiently render and optimize this scene, we will use the Particle Tracer integrator (`ptracer`), which traces rays from the emitter rather than the sensor.\n",
    "\n",
    "<img alt=\"Caustic Optimization diagram\" src=\"data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 25.3.1, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 855.57 794.9" style="enable-background:new 0 0 855.57 794.9;" xml:space="preserve">
<style type="text/css">
	.st0{fill:none;stroke:#000000;stroke-width:2;stroke-linecap:round;stroke-miterlimit:10;}
	.st1{fill:#999999;}
	.st2{fill:none;stroke:#000000;stroke-width:1.5;stroke-miterlimit:10;}
	.st3{fill:#FFD577;}
	.st4{fill:#FFFFFF;}
	.st5{fill:none;stroke:#787878;stroke-width:1.5;stroke-linecap:round;stroke-linejoin:round;stroke-miterlimit:10;}
	.st6{fill:#E9CB1C;}
	.st7{fill:none;stroke:#000000;stroke-miterlimit:10;}
	.st8{fill:none;stroke:#000000;stroke-width:1.5;stroke-linecap:round;stroke-linejoin:round;stroke-miterlimit:10;}
	.st9{opacity:0.5;}
	.st10{clip-path:url(#SVGID_2_);fill:#3B7DC0;}
	.st11{clip-path:url(#SVGID_4_);fill:#3B7DC0;}
	.st12{fill:#BCBCBC;}
	.st13{font-family:'LinLibertine';}
	.st14{font-size:50px;}
</style>
<line class="st0" x1="341.25" y1="71.81" x2="341.25" y2="212.99"/>
<line class="st0" x1="155.9" y1="637.79" x2="155.9" y2="737.95"/>
<polygon class="st1" points="466.58,86.81 833.58,97.81 782.58,700.81 466.58,491.81 "/>
<polygon class="st2" points="466.58,86.81 833.58,97.81 782.58,700.81 466.58,491.81 "/>
<line class="st0" x1="639.14" y1="71.14" x2="639.14" y2="212.99"/>
<path class="st3" d="M530.11,359.13c-7.38-41.69-1.97-73.4,4.18-93.16c8.25-26.51,22.89-47.42,40.16-57.37
	c8.71-5.02,18.24-7.56,28.35-7.56c29.43,0,60.74,21.65,79.41,54.43c-8.05-2.12-16.44-3.19-25-3.19
	C610.51,252.28,554.26,285.42,530.11,359.13"/>
<path class="st4" d="M602.79,198.54l0.01,5c14.72,0,30.16,5.6,44.64,16.18c11.5,8.4,21.59,19.33,29.6,32
	c-6.45-1.28-13.09-1.93-19.83-1.93c-27.34,0-55.17,10.72-78.35,30.18c-20.74,17.41-37.04,41.03-47.79,69.05
	c-4.93-36.45,0.03-64.38,5.62-82.31c8.07-25.91,22.29-46.3,39.02-55.94c8.32-4.8,17.44-7.23,27.1-7.23V198.54 M602.8,198.54
	c-10.16,0-20.2,2.48-29.6,7.9c-34.46,19.85-61.13,82.58-43.6,163.03c20.87-75.54,76.48-114.68,127.6-114.68
	c10.31,0,20.44,1.59,30.06,4.8C669.05,223.89,635.29,198.54,602.8,198.54"/>
<path class="st3" d="M566.39,402.19c-13.11,0-21.83-4.67-25.92-13.86c-7.58-17.03,2.16-47.01,22.64-69.74
	c24.43-27.1,62.05-56.05,94.39-56.05c9.4,0,17.95,2.45,25.55,7.29c-3.29-0.7-6.81-1.05-10.55-1.05c-26.25,0-69.96,20.32-97.66,54.32
	c-18.94,23.24-25.97,47.65-18.35,63.68c3.69,7.76,10.43,12.81,19.36,14.68C572.51,401.95,569.36,402.19,566.39,402.19L566.39,402.19
	z"/>
<path class="st4" d="M657.51,265.04c3.92,0,7.69,0.45,11.29,1.35c-33.54,1.9-74.56,28.95-95.89,55.14
	c-9.8,12.03-16.67,24.55-19.86,36.21c-3.14,11.46-2.72,21.88,1.19,30.13c2.38,5,5.89,8.97,10.35,11.8
	c-11.02-0.4-18.36-4.55-21.83-12.34c-7.08-15.92,2.67-45.37,22.21-67.05C589.03,293.56,625.98,265.04,657.51,265.04 M657.51,260.04
	c-33.72,0-71.73,29.67-96.25,56.88c-30.7,34.06-39.82,87.77,5.14,87.77c11.01,0,25.26-3.22,43.23-10.74
	c-9.68,4-18.26,5.82-25.55,5.82c-32.28,0-39.45-35.63-7.3-75.09c22.48-27.58,64.46-53.4,95.72-53.4c9.61,0,18.2,2.44,24.91,8.01
	C685.87,265.59,672.09,260.04,657.51,260.04"/>
<path class="st3" d="M585.42,434.41c-8.12,0-15.34-1.42-21.53-4.2c2.71,0.48,5.57,0.73,8.58,0.73h0.01
	c31.2-0.01,73.18-25.63,93.59-57.13c17.15-26.47,15.23-42.18,10.6-50.7c-5.29-9.73-16.88-15.09-32.63-15.09
	c-2.73,0-5.58,0.16-8.52,0.48c15.63-5.8,29.82-8.8,41.85-8.8c14.28,0,24.39,4.36,29.25,12.62c6.79,11.55,3.47,30.06-9.6,53.53
	c-9.57,17.18-27.27,34.58-48.57,47.73C627.02,426.82,604.05,434.41,585.42,434.41L585.42,434.41z"/>
<path class="st4" d="M677.37,302.2c9.3,0,21.56,1.98,27.09,11.39c6.22,10.59,2.8,28.72-9.63,51.05
	c-9.36,16.82-26.75,33.88-47.7,46.82c-20.54,12.68-42.45,20.09-60.39,20.44c29.49-6.05,63.57-29.19,81.42-56.73
	c17.82-27.5,15.65-44.14,10.7-53.25c-4.82-8.86-14.28-14.38-27.06-15.94C661.18,303.49,669.81,302.2,677.37,302.2 M677.37,297.2
	c-17.92,0-41.58,6.66-68.34,20.31c12.93-4.7,24.86-6.99,35.01-6.99c31.48,0,45.82,21.98,19.93,61.93
	c-19.74,30.46-61.17,55.99-91.49,55.99c-11.88,0-22.05-3.92-28.54-12.99c8.84,15.14,23.93,21.46,41.48,21.46
	c40.24,0,93.41-33.24,113.78-69.83C724.73,321.24,711.41,297.2,677.37,297.2"/>
<path class="st3" d="M641.55,508.7c-16.43,0-32.8-5.98-47.35-17.28c-14.81-11.51-27.34-27.98-37.29-49.01
	c7.5,3.16,16.21,4.76,25.97,4.76h0.01c25.31,0,54.59-10.67,80.33-29.28c25.63-18.52,44.68-42.87,54.35-69.22
	c15.39,57.56,2.97,115.79-31.28,143.68C673.13,503.04,657.67,508.7,641.55,508.7L641.55,508.7z"/>
<path class="st4" d="M717,356.77c5.61,24.77,6.13,49.57,1.42,72.51c-5.35,26.07-17.32,47.78-33.71,61.12
	c-12.7,10.33-27.62,15.8-43.15,15.8c-15.87,0-31.71-5.79-45.82-16.76c-13.19-10.25-24.54-24.55-33.85-42.61
	c6.35,1.89,13.37,2.84,21,2.84c25.83,0,55.64-10.84,81.8-29.75C688.35,402.81,706.5,380.79,717,356.77 M717.72,340.2
	c-18.26,62.48-86.04,104.46-134.84,104.46c-11.84,0-22.55-2.47-31.18-7.72c22.16,51.51,57.12,74.25,89.85,74.25
	c16.68,0,32.78-5.9,46.31-16.92C722.89,465.77,737.42,403.51,717.72,340.2"/>
<polyline class="st5" points="279.58,196.81 294.58,498.48 449.83,640.81 "/>
<line class="st5" x1="261.58" y1="506.81" x2="294.58" y2="498.48"/>
<polygon class="st6" points="571.59,269.59 550.77,260.87 554.79,267.94 351.09,266.09 351,266.09 306.15,271.19 306.49,274.17 
	351.16,269.09 554.77,270.94 550.62,277.94 "/>
<polygon class="st7" points="571.59,269.59 550.77,260.87 554.79,267.94 351.09,266.09 351,266.09 306.15,271.19 306.49,274.17 
	351.16,269.09 554.77,270.94 550.62,277.94 "/>
<polygon class="st6" points="539.55,311.52 519.11,301.94 522.84,309.17 414.88,303.72 414.73,303.71 358.44,312.07 358.88,315.04 
	414.88,306.72 522.69,312.17 518.25,318.99 "/>
<polygon class="st7" points="539.55,311.52 519.11,301.94 522.84,309.17 414.88,303.72 414.73,303.71 358.44,312.07 358.88,315.04 
	414.88,306.72 522.69,312.17 518.25,318.99 "/>
<polygon class="st6" points="556.65,336.66 535.09,329.95 539.77,336.61 341.12,353.78 291.02,362.62 291.54,365.58 341.45,356.77 
	540.03,339.6 536.56,346.96 "/>
<polygon class="st7" points="556.65,336.66 535.09,329.95 539.77,336.61 341.12,353.78 291.02,362.62 291.54,365.58 341.45,356.77 
	540.03,339.6 536.56,346.96 "/>
<polygon class="st6" points="689.4,336.66 667.49,331.22 672.55,337.59 364.43,382.43 303.65,393.91 304.2,396.86 364.92,385.38 
	672.98,340.56 669.95,348.12 "/>
<polygon class="st7" points="689.4,336.66 667.49,331.22 672.55,337.59 364.43,382.43 303.65,393.91 304.2,396.86 364.92,385.38 
	672.98,340.56 669.95,348.12 "/>
<polygon class="st6" points="543.94,384.43 521.37,384.89 527.92,389.72 321.22,479.15 261.61,492.86 262.28,495.79 322.16,482.01 
	529.11,392.48 528.15,400.56 "/>
<polygon class="st7" points="543.94,384.43 521.37,384.89 527.92,389.72 321.22,479.15 261.61,492.86 262.28,495.79 322.16,482.01 
	529.11,392.48 528.15,400.56 "/>
<polygon class="st6" points="665.26,458.85 643.08,454.64 648.49,460.72 390.18,513.18 325.09,531.24 325.89,534.13 390.83,516.11 
	649.09,463.66 646.48,471.37 "/>
<polygon class="st7" points="665.26,458.85 643.08,454.64 648.49,460.72 390.18,513.18 325.09,531.24 325.89,534.13 390.83,516.11 
	649.09,463.66 646.48,471.37 "/>
<polyline class="st8" points="409.58,655.81 261.58,506.81 244.58,200.81 "/>
<g class="st9">
	<g>
		<defs>
			<rect id="SVGID_1_" x="244.58" y="200.81" width="165" height="455"/>
		</defs>
		<clipPath id="SVGID_2_">
			<use xlink:href="#SVGID_1_"  style="overflow:visible;"/>
		</clipPath>
		<polygon class="st10" points="244.58,200.81 261.58,506.81 409.58,655.81 401.58,251.81 		"/>
	</g>
</g>
<g class="st9">
	<g>
		<defs>
			<rect id="SVGID_3_" x="244.58" y="196.84" width="206.6" height="459.31"/>
		</defs>
		<clipPath id="SVGID_4_">
			<use xlink:href="#SVGID_3_"  style="overflow:visible;"/>
		</clipPath>
		<path class="st11" d="M401.58,251.81l8,404.33l40.24-15c-1.76-7.43-2.78-14.31-0.2-18.5c1.37-10.61,2.79-21.28-0.29-26.51
			c0.7-5.39,0.8-10.47-0.16-14.99c-2.52-4.58-2.37-9.79-0.17-15.49c1.54-6.97,0.75-17.53-0.31-28.51c-1.52-12.41-1.98-24.01-0.36-34
			c1.79-7.77,2.35-14.48-0.2-18.5c2.13-16.08,2.58-30.88-0.46-43l-0.14-12.99c-1.95-15.05-3.04-29.13-0.42-39.01
			c1.66-4.52,0.9-10.88-0.19-17.49c-4.19-14.02-2.78-31.03-0.52-48.49c0.75-20.8,1.5-41.6-0.56-52c-2.82-8.5-3.14-17-0.27-25.51
			c-13.46-2.18-26.61-4.43-30.31-8.95c-6.98-3.07-14.18-5.88-22.92-6.77c-10.48-1.33-19.14-3.09-21.46-6.33
			c-4.91,0.35-8.37-0.32-9.31-2.75c-7.36-0.35-13.59-1.52-16.72-4.94c-6.51-3.14-13.33-5.77-21.4-6.32
			c-8.91,0.45-9.87-0.45-10.93-3.23c-5.22-3.79-11.43-7.01-23.38-6.9c-1.79-2.5-4.7-3.74-9.55-2.82l-35,4l82.5,26.47"/>
	</g>
</g>
<path class="st8" d="M244.58,200.81l35-4c4.85-0.92,7.76,0.32,9.55,2.82c11.96-0.11,18.16,3.11,23.38,6.9
	c1.07,2.78,2.03,3.67,10.93,3.23c8.08,0.55,14.9,3.18,21.4,6.32c3.13,3.42,9.37,4.58,16.72,4.94c0.94,2.43,4.4,3.1,9.31,2.75
	c2.32,3.24,10.98,5,21.46,6.33c8.74,0.88,15.94,3.69,22.92,6.77c3.71,4.51,16.85,6.77,30.31,8.95c-2.86,8.5-2.55,17.01,0.27,25.51
	c2.06,10.4,1.31,31.2,0.56,52c-2.26,17.46-3.67,34.47,0.52,48.49c1.09,6.61,1.85,12.98,0.19,17.49c-2.62,9.87-1.53,23.95,0.42,39.01
	l0.14,12.99c3.04,12.12,2.59,26.92,0.46,43c2.55,4.02,1.99,10.73,0.2,18.5c-1.61,9.99-1.15,21.59,0.37,34
	c1.06,10.98,1.85,21.54,0.31,28.51c-2.2,5.7-2.35,10.91,0.17,15.49c0.96,4.52,0.86,9.6,0.16,14.99c3.07,5.23,1.66,15.9,0.29,26.51
	c-2.58,4.19-1.56,11.07,0.2,18.5l-40.24,15l-8-404l44-6"/>
<line class="st8" x1="401.58" y1="251.81" x2="244.58" y2="200.81"/>
<polygon class="st6" points="329.66,270.03 307.94,263.91 312.79,270.44 145.73,289.42 146.07,292.41 313.13,273.42 309.86,280.87 
	"/>
<polygon class="st7" points="329.66,270.03 307.94,263.91 312.79,270.44 145.73,289.42 146.07,292.41 313.13,273.42 309.86,280.87 
	"/>
<polygon class="st6" points="377.56,310.75 355.64,305.37 360.72,311.73 161.5,341.31 161.94,344.28 361.16,314.7 358.15,322.26 "/>
<polygon class="st7" points="377.56,310.75 355.64,305.37 360.72,311.73 161.5,341.31 161.94,344.28 361.16,314.7 358.15,322.26 "/>
<polygon class="st6" points="315.58,359.81 293.52,355.04 298.77,361.25 145.49,388.32 146.01,391.27 299.29,364.21 296.49,371.85 
	"/>
<polygon class="st7" points="315.58,359.81 293.52,355.04 298.77,361.25 145.49,388.32 146.01,391.27 299.29,364.21 296.49,371.85 
	"/>
<polygon class="st6" points="336.08,389.31 313.97,384.8 319.29,390.96 155.99,421.82 156.54,424.77 319.85,393.9 317.14,401.58 "/>
<polygon class="st7" points="336.08,389.31 313.97,384.8 319.29,390.96 155.99,421.82 156.54,424.77 319.85,393.9 317.14,401.58 "/>
<polygon class="st6" points="288.08,488.31 265.81,484.68 271.37,490.62 157.46,516.82 158.14,519.75 272.04,493.54 269.64,501.31 
	"/>
<polygon class="st7" points="288.08,488.31 265.81,484.68 271.37,490.62 157.46,516.82 158.14,519.75 272.04,493.54 269.64,501.31 
	"/>
<polygon class="st6" points="361.08,522.81 338.67,520.17 344.49,525.86 164.44,575.83 165.25,578.72 345.29,528.75 343.23,536.62 
	"/>
<polygon class="st7" points="361.08,522.81 338.67,520.17 344.49,525.86 164.44,575.83 165.25,578.72 345.29,528.75 343.23,536.62 
	"/>
<polygon class="st12" points="69.19,213.91 173.68,277.91 174.45,287.82 208.49,727.88 102.58,546.81 "/>
<polygon class="st2" points="69.19,213.91 173.68,277.91 174.45,287.82 208.49,727.88 102.58,546.81 "/>
<text transform="matrix(1 0 0 1 495.1745 43.9838)"><tspan x="0" y="0" class="st13 st14">P</tspan><tspan x="27.03" y="0" class="st13 st14">r</tspan><tspan x="45.21" y="0" class="st13 st14">oj</tspan><tspan x="84" y="0" class="st13 st14">e</tspan><tspan x="106.64" y="0" class="st13 st14">ct</tspan><tspan x="143.82" y="0" class="st13 st14">e</tspan><tspan x="166.46" y="0" class="st13 st14">d caustic</tspan></text>
<text transform="matrix(1 0 0 1 7.1247 43.9838)"><tspan x="0" y="0" class="st13 st14">Optimiz</tspan><tspan x="164.58" y="0" class="st13 st14">e</tspan><tspan x="187.16" y="0" class="st13 st14">d g</tspan><tspan x="249.96" y="0" class="st13 st14">e</tspan><tspan x="272.6" y="0" class="st13 st14">omet</tspan><tspan x="375.4" y="0" class="st13 st14">r</tspan><tspan x="394.68" y="0" class="st13 st14">y</tspan></text>
<text transform="matrix(1 0 0 1 89.6247 774.5834)"><tspan x="0" y="0" class="st13 st14">Di</tspan><tspan x="48.58" y="0" class="st13 st14">r</tspan><tspan x="66.76" y="0" class="st13 st14">e</tspan><tspan x="89.4" y="0" class="st13 st14">ctional a</tspan><tspan x="263.77" y="0" class="st13 st14">r</tspan><tspan x="281.9" y="0" class="st13 st14">ea light</tspan></text>
</svg>
\" width=\"50%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing Mitsuba and selecting an appropriate variant supporting automatic differentiation (AD). AD support is required to compute gradients with respect to the slab's surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# If `setpath.sh` has not been sourced before starting the notebook server,\n",
    "# you can manually add the path to Mitsuba's build directory here.\n",
    "mts_py_path = '../../../build/python'\n",
    "if mts_py_path not in sys.path:\n",
    "    sys.path.append(mts_py_path)\n",
    "        \n",
    "import os\n",
    "from os.path import join, realpath, dirname\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import enoki as ek\n",
    "    import mitsuba\n",
    "except ImportError as e:\n",
    "    print('Could not import Enoki and Mitsuba, have you sourced `setpath`?', file=sys.stderr)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use automatic differentiation, we need to enable a variant that supports it. Those are the ones containing `_ad` after the backend description. E.g. `cuda_ad_rgb`, `llvm_ad_rgb`, ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_variants = ['cuda_ad_rgb', 'llvm_ad_rgb']\n",
    "for v in desired_variants:\n",
    "    if v in mitsuba.variants():\n",
    "        mitsuba.set_variant(v)\n",
    "        break\n",
    "else:\n",
    "    raise RuntimeError('Must enable at least one of the following variants: ' + str(desired_variants))\n",
    "\n",
    "# AD mode: do not use symbolic recording.\n",
    "ek.set_flag(ek.JitFlag.LoopRecord, False)\n",
    "ek.set_flag(ek.JitFlag.VCallRecord, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - choosing a configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we can attempt to reproduce either a grayscale image using a uniform emitter, or a color image using an RGB emitter. Here, we define those two options and select one.\n",
    "\n",
    "Feel free to define additional configurations, e.g. to target a different reference image of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENE_DIR = realpath('../scenes')\n",
    "COMMON_OPTIONS = {\n",
    "    'render_resolution': (512, 512),\n",
    "    'heightmap_resolution': (512, 512),\n",
    "    'spp': 32,\n",
    "    'max_iterations': 500,\n",
    "    'learning_rate': 2e-5,\n",
    "}\n",
    "CONFIGS = {\n",
    "    'wave': dict(**{\n",
    "        'emitter': 'gray',\n",
    "        'reference': join(SCENE_DIR, 'references/wave-1024.jpg'),\n",
    "    }, **COMMON_OPTIONS),\n",
    "    'sunday': dict(**{\n",
    "        'emitter': 'bayer',\n",
    "        'reference': join(SCENE_DIR, 'references/sunday-512.jpg'),\n",
    "    }, **COMMON_OPTIONS),\n",
    "}\n",
    "\n",
    "# Pick one of the available configs\n",
    "config_name = 'sunday'  # 'wave'\n",
    "config = CONFIGS[config_name]\n",
    "print('[i] Reference image selected:', config['reference'])\n",
    "\n",
    "output_dir = realpath(join('.', 'outputs', config_name))\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print('[i] Results will be saved to:', output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - creating the scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the chosen configuration, a different type of emitter will need to be used. For this reason, we define the scene dynamically directly from Python as a dictionary and load it with `mitsuba.core.xml.load_dict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mitsuba.core import ScalarTransform4f, Thread, Bitmap\n",
    "from mitsuba.core.xml import load_dict\n",
    "\n",
    "# Make sure that resources from the scene directory can be found\n",
    "fr = Thread.thread().file_resolver()\n",
    "fr.append(SCENE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the lens mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the optimization is to recover the heightfield that needs to be applied to a slab of glass so that it focuses light in just the right way to reproduce the desired target image.\n",
    "\n",
    "The heightmap will be represented as a texture and applied to the slab's vertices. For this technique to be effective, the slab must have enough geometric resolution (vertices) to match the heightmap texture.\n",
    "\n",
    "Here, we generate the appropriate mesh directly from Python: a simple tesselated plane with the desired resolution and save it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flat_lens_mesh(resolution):\n",
    "    from mitsuba.core import Float, UInt32, Vector2f, Vector3f\n",
    "    from mitsuba.render import Mesh\n",
    "\n",
    "    assert resolution[0] == resolution[1], 'Not supported yet: non-square lens mesh resolution'\n",
    "    U, V = ek.meshgrid(\n",
    "        ek.linspace(Float, 0, 1, resolution[0]),\n",
    "        ek.linspace(Float, 0, 1, resolution[1]),\n",
    "        indexing='ij'\n",
    "    )\n",
    "    X = 2 * (U - 0.5)\n",
    "    Y = 2 * (V - 0.5)\n",
    "\n",
    "    n_vertices = resolution[0] * resolution[1]\n",
    "    vertices = Vector3f(X, Y, ek.zero(Float, n_vertices))\n",
    "    texcoords = Vector2f(U, V)\n",
    "\n",
    "    # Create two triangles per grid cell\n",
    "    faces = []\n",
    "    for i in range(resolution[0] - 1):\n",
    "        for j in range(resolution[1] - 1):\n",
    "            v00 = i * resolution[1] + j\n",
    "            v01 = v00 + 1\n",
    "            v10 = (i + 1) * resolution[1] + j\n",
    "            v11 = v10 + 1\n",
    "\n",
    "            faces.append((v00, v10, v01))\n",
    "            faces.append((v01, v10, v11))\n",
    "    n_faces = len(faces)\n",
    "    faces = np.array(faces).astype(np.uint32)\n",
    "    assert faces.shape == (n_faces, 3)\n",
    "\n",
    "    m = Mesh(\"lens-mesh\", n_vertices, n_faces, has_vertex_texcoords=True)\n",
    "    ek.scatter(\n",
    "        m.vertex_positions_buffer(), ek.ravel(vertices),\n",
    "        ek.arange(UInt32, n_vertices * 3)\n",
    "    )\n",
    "    ek.scatter(\n",
    "        m.faces_buffer(), UInt32(faces.ravel()),\n",
    "        ek.arange(UInt32, n_faces * 3)\n",
    "    )\n",
    "    ek.scatter(\n",
    "        m.vertex_texcoords_buffer(), ek.ravel(texcoords),\n",
    "        ek.arange(UInt32, n_vertices * 2)\n",
    "    )\n",
    "    ek.eval()\n",
    "    m.parameters_changed()\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_res = config.get('lens_res', config['heightmap_resolution'])\n",
    "lens_fname = join(output_dir, 'lens_{}_{}.ply'.format(*lens_res))\n",
    "if not os.path.isfile(lens_fname):\n",
    "    m = create_flat_lens_mesh(lens_res)\n",
    "    m.write_ply(lens_fname)\n",
    "    print('[+] Wrote lens mesh ({}x{} tesselation) file to: {}'.format(*lens_res, lens_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the appropriate emitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained previously, depending on whether we are trying to reproduce a grayscale or colorful target image, we setup the emitter to either emit constant white light or an RGB Bayer pattern.\n",
    "In the latter case, the pattern is generated on-the-fly and passed to the emitter as an in-memory `Bitmap` texture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitter = None\n",
    "if config['emitter'] == 'gray':\n",
    "    emitter = {\n",
    "        'type':'directionalarea',\n",
    "        'radiance': {'type': 'spectrum', 'value': 0.8},\n",
    "    }\n",
    "elif config['emitter'] == 'bayer':\n",
    "    bayer = np.zeros(shape=(32, 32, 3))\n",
    "    bayer[::2, ::2, 2] = 2.2\n",
    "    bayer[::2, 1::2, 1] = 2.2\n",
    "    # bayer[1::2, ::2, 1] = 1  # Avoid too much green\n",
    "    bayer[1::2, 1::2, 0] = 2.2\n",
    "\n",
    "    bayer = Bitmap(bayer.astype(np.float32), pixel_format=Bitmap.PixelFormat.RGB)\n",
    "    # bayer.write('emitter.exr')\n",
    "    emitter = {\n",
    "        'type':'directionalarea',\n",
    "        'radiance': {\n",
    "            'type': 'bitmap',\n",
    "            'bitmap': bayer,\n",
    "            'raw': True,\n",
    "            'filter_type': 'nearest'\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the rest of the scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sensor looks directly at the receiving plane where the caustic will be formed. The light source and optimized lens will stand behind the camera.\n",
    "Note that since the camera is an idealized pinhole camera and does not occupy any space, it will not cast any shadow on the receiving plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the receiving plane, not looking through the lens\n",
    "sensor_to_world = ScalarTransform4f.look_at(\n",
    "    target=(0, -20, 0),\n",
    "    origin=(0, -4.65, 0),\n",
    "    up=(0, 0, 1)\n",
    ")\n",
    "resx, resy = config['render_resolution']\n",
    "sensor = {\n",
    "    'type': 'perspective',\n",
    "    'near_clip': 1,\n",
    "    'far_clip': 1000,\n",
    "    'fov': 45,\n",
    "    'to_world': sensor_to_world,\n",
    "\n",
    "    'sampler': {\n",
    "        'type': 'independent',\n",
    "        'sample_count': 512  # Not really used\n",
    "    },\n",
    "    'film': {\n",
    "        'type': 'hdrfilm',\n",
    "        'width': resx,\n",
    "        'height': resy,\n",
    "        'pixel_format': 'rgb',\n",
    "        'rfilter': {\n",
    "            # Important: smooth reconstruction filter with a footprint larger than 1 pixel.\n",
    "            'type': 'gaussian'\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen light source emits light in a single direction, which would be very difficult (or impossible) to sample correctly with a standard path tracer. For this reason, we use a particle tracer (`ptracer`), which starts rays from the emitters rather than the sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrator = {\n",
    "    'type': 'ptracer',\n",
    "    'samples_per_pass': 256,\n",
    "    'max_depth': 4,\n",
    "    'hide_emitters': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now put everything together into a single large dictionary, where we also define the remaining geometry (receiving plane, geometry, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = {\n",
    "    'type': 'scene',\n",
    "    'sensor': sensor,\n",
    "    'integrator': integrator,\n",
    "    # Glass BSDF\n",
    "    'simple-glass': {\n",
    "        'type': 'dielectric',\n",
    "        'id': 'simple-glass-bsdf',\n",
    "        'ext_ior': 'air',\n",
    "        'int_ior': 1.5,\n",
    "        'specular_reflectance': { 'type': 'spectrum', 'value': 0 },\n",
    "    },\n",
    "    'white-bsdf': {\n",
    "        'type': 'diffuse',\n",
    "        'id': 'white-bsdf',\n",
    "        'reflectance': { 'type': 'rgb', 'value': (1, 1, 1) },\n",
    "    },\n",
    "    'black-bsdf': {\n",
    "        'type': 'diffuse',\n",
    "        'id': 'black-bsdf',\n",
    "        'reflectance': { 'type': 'spectrum', 'value': 0 },\n",
    "    },\n",
    "\n",
    "    # Receiving plane\n",
    "    'receiving-plane': {\n",
    "        'type': 'obj',\n",
    "        'id': 'receiving-plane',\n",
    "        'filename': 'meshes/rectangle.obj',\n",
    "        'to_world': \\\n",
    "            ScalarTransform4f.look_at(\n",
    "                target=(0, 1, 0),\n",
    "                origin=(0, -7, 0),\n",
    "                up=(0, 0, 1)\n",
    "            ) \\\n",
    "            * ScalarTransform4f.scale((5, 5, 5)),\n",
    "        'bsdf': {'type': 'ref', 'id': 'white-bsdf'},\n",
    "    },\n",
    "    # Glass slab, excluding the 'exit' face (added separately below)\n",
    "    'slab': {\n",
    "        'type': 'obj',\n",
    "        'id': 'slab',\n",
    "        'filename': 'meshes/slab.obj',\n",
    "        'to_world': ScalarTransform4f.rotate(axis=(1, 0, 0), angle=90),\n",
    "        'bsdf': {'type': 'ref', 'id': 'simple-glass'},\n",
    "    },\n",
    "    # Glass rectangle, to be optimized\n",
    "    'lens': {\n",
    "        'type': 'ply',\n",
    "        'id': 'lens',\n",
    "        'filename': lens_fname,\n",
    "        'to_world': ScalarTransform4f.rotate(axis=(1, 0, 0), angle=90),\n",
    "        'bsdf': {'type': 'ref', 'id': 'simple-glass'},\n",
    "    },\n",
    "\n",
    "    # Directional area emitter placed behind the glass slab\n",
    "    'focused-emitter-shape': {\n",
    "        'type': 'obj',\n",
    "        'filename': 'meshes/rectangle.obj',\n",
    "        'to_world': ScalarTransform4f.look_at(\n",
    "            target=(0, 0, 0),\n",
    "            origin=(0, 5, 0),\n",
    "            up=(0, 0, 1)\n",
    "        ),\n",
    "        'bsdf': {'type': 'ref', 'id': 'black-bsdf'},\n",
    "        'focused-emitter': emitter,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the scene is loaded which instantiates all of the appropriate plugins, loads the geometry, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = load_dict(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - loading the reference image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the sensor has been defined, we can load the reference image and ensure that its resolution matches the render resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ref_image(config, resolution, output_dir):\n",
    "    from mitsuba.core import Bitmap, Float\n",
    "    from mitsuba.python.util import write_bitmap\n",
    "\n",
    "    b = Bitmap(config['reference'])\n",
    "    b = b.convert(Bitmap.PixelFormat.RGB, Bitmap.Float32, False)\n",
    "    if b.size() != resolution:\n",
    "        b = b.resample(resolution)\n",
    "\n",
    "    image_ref = np.array(b)\n",
    "    write_bitmap(join(output_dir, 'out_ref.exr'), image_ref, resolution)\n",
    "    \n",
    "    print('[i] Loaded reference image from:', config['reference'])\n",
    "    return Float(image_ref.ravel())\n",
    "\n",
    "# Make sure the reference image will have a resolution matching the sensor\n",
    "sensor = scene.sensors()[0]\n",
    "crop_size = sensor.film().crop_size()\n",
    "image_ref = load_ref_image(config, crop_size, output_dir=output_dir)\n",
    "ref_scale = ek.hmean(image_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - creating the displacement texture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than optimizing the unconstrained vertex positions of the lens directly, we optimize values of a high-resolution heightmap. Here, we create the heightmap texture and create an optimizer that will work on its values.\n",
    "\n",
    "Notice how the `traverse` method is used directly on our new texture object, rather than on the scene loaded earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mitsuba.core import Vector3f\n",
    "from mitsuba.core.xml import load_dict\n",
    "from mitsuba.render import SurfaceInteraction3f\n",
    "from mitsuba.python.util import traverse\n",
    "from mitsuba.python.ad.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heightmap_texture = load_dict({\n",
    "    'type': 'bitmap',\n",
    "    'id': 'heightmap_texture',\n",
    "    'bitmap': Bitmap(np.zeros(config['heightmap_resolution'], dtype=np.float32)),\n",
    "    'raw': True,\n",
    "}).expand()[0]\n",
    "\n",
    "# Actually optimized: the heightmap texture\n",
    "params = traverse(heightmap_texture)\n",
    "params.keep(['data'])\n",
    "opt = Adam(lr=config['learning_rate'], params=params)\n",
    "opt.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each iteration, the lens' vertices will displaced from their original position along their normal by the value of the heightmap.\n",
    "Don't forget that the geometric resolution of the lens mesh (number of vertices) must also be high enough for this technique to work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_scene = traverse(scene)\n",
    "# We will always apply displacements along the original normals and\n",
    "# starting from the original positions.\n",
    "positions_initial = ek.unravel(Vector3f, params_scene['lens.vertex_positions'])\n",
    "normals_initial = ek.unravel(Vector3f, params_scene['lens.vertex_normals'])\n",
    "lens_si = ek.zero(SurfaceInteraction3f, ek.width(positions_initial))\n",
    "lens_si.uv = ek.unravel(type(lens_si.uv), params_scene['lens.vertex_texcoords'])\n",
    "\n",
    "\n",
    "def apply_displacement(amplitude = 1.):\n",
    "    # Enforce reasonable range. For reference, the receiving plane\n",
    "    # is 7 scene units away from the lens.\n",
    "    vmax = 1 / 100.\n",
    "    params['data'] = ek.clamp(params['data'], -vmax, vmax)\n",
    "    ek.enable_grad(params['data'])\n",
    "\n",
    "    new_positions = (heightmap_texture.eval_1(lens_si) * normals_initial * amplitude\n",
    "                        + positions_initial)\n",
    "    params_scene['lens.vertex_positions'] = ek.ravel(new_positions)\n",
    "    params_scene.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - running the optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're finally ready to start the optimization itself!\n",
    "\n",
    "At each iteration, we apply the current heightmap displacement to the lens surface and render the scene with automatic differentiation enabled.\n",
    "\n",
    "We then compare the render to our target image with a scale-independent L2 loss.\n",
    "We divide out the average brightness in the loss so that the general brightness of the emitter (set arbitrarily) does not interfere with the optimization.\n",
    "\n",
    "After backpropagating through the computation graph, we use the gradients of the loss w.r.t. the heightmap values to update the heightmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mitsuba.core import Bitmap, Thread, LogLevel\n",
    "from mitsuba.python.util import write_bitmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrator = scene.integrator()\n",
    "logger = Thread.thread().logger()\n",
    "\n",
    "start_time = time.time()\n",
    "logger.set_log_level(LogLevel.Warn)\n",
    "iterations = config['max_iterations']\n",
    "loss_values = []\n",
    "for it in range(iterations):\n",
    "    t0 = time.time()\n",
    "\n",
    "    apply_displacement()\n",
    "\n",
    "    # Perform a differentiable rendering of the scene\n",
    "    image = integrator.render(scene, seed=it, spp=config['spp'])\n",
    "    image = image.array  # From TensorXf to Float\n",
    "\n",
    "    if (it % 5 == 0) or (it == iterations - 1):\n",
    "        write_bitmap(join(output_dir, 'out_{:03d}.exr'.format(it)),\n",
    "                     image, crop_size)\n",
    "\n",
    "    # -- Loss function\n",
    "    current_scale = ek.hsum(ek.detach(image)) / ek.width(image)\n",
    "    # Scale-independent L2\n",
    "    diff = (image / current_scale) - (image_ref / ref_scale)\n",
    "    # # Scale-independent relative L2\n",
    "    # diff = ((image / current_scale) - (image_ref / ref_scale)) / (0.01 + image_ref / ref_scale)\n",
    "    loss = ek.hmean_async(ek.sqr(diff))\n",
    "\n",
    "    # Back-propagate errors to input parameters and take an optimizer step\n",
    "    ek.backward(loss)\n",
    "    opt.step()\n",
    "    # Carry over the update to our \"latent variable\" (the heightmap values)\n",
    "    opt.update()\n",
    "    \n",
    "    # In order to improve kernel reuse, ensure that the state of \n",
    "    # the RNG is updated in this loop iteration rather than at the\n",
    "    # start of the next one.\n",
    "    sensor.sampler().schedule_state()\n",
    "\n",
    "    elapsed_ms = 1000. * (time.time() - t0)\n",
    "    current_loss = loss[0]\n",
    "    loss_values.append(current_loss)\n",
    "    logger.log_progress(\n",
    "        it / (iterations-1), \n",
    "        f'Iteration {it:03d}: loss={current_loss:g} (took {elapsed_ms:.0f}ms)',\n",
    "        'Caustic Optimization', '')\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(((end_time - start_time) * 1000) / iterations, ' ms per iteration on average')\n",
    "logger.set_log_level(LogLevel.Info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the optimization has completed, we save the final heightmap and the corresponding lens with displacement applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = join(output_dir, 'heightmap_final.exr')\n",
    "write_bitmap(fname, params['data'], config['heightmap_resolution'])\n",
    "print('[+] Saved final heightmap state to:', fname)\n",
    "\n",
    "fname = join(output_dir, 'lens_displaced.ply')\n",
    "apply_displacement()\n",
    "lens_mesh = [m for m in scene.shapes() if m.id() == 'lens'][0]\n",
    "lens_mesh.write_ply(fname)\n",
    "print('[+] Saved displaced lens to:', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the evolution of the loss and show the final result next to the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mitsuba.python.util import convert_to_bitmap\n",
    "\n",
    "def show_image(ax, img, title):\n",
    "    ax.imshow(convert_to_bitmap(img, crop_size))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "def show_heightmap(fig, ax, values, title):\n",
    "    values = params['data'].numpy().reshape(crop_size)\n",
    "    im = ax.imshow(values)\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(11, 10))\n",
    "ax = ax.ravel()\n",
    "ax[0].plot(loss_values)\n",
    "ax[0].set_xlabel('Iteration'); ax[0].set_ylabel('Loss value'); ax[0].set_title('Convergence plot')\n",
    "\n",
    "show_heightmap(fig, ax[1], params['data'], 'Final heightmap')\n",
    "show_image(ax[2], image_ref, 'Reference')\n",
    "show_image(ax[3], image, 'Final state')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Feel free to define your own target images at the top of the notebook and run this tutorial again.\n",
    "\n",
    "If you would like to improve the quality of the results, you could try the following:\n",
    "- Letting the optimization run for more iterations\n",
    "- Tweaking the learning rate and sample count\n",
    "- Progressively increasing the resolution of the heightmap through optimization, e.g. starting from a 16x16 heightmap and doubling the resolution every N iterations."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
